# predict.py
from cog import BasePredictor, Input, Path
import torch
import cv2
import numpy as np
from PIL import Image
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler

class Predictor(BasePredictor):
    def setup(self):
        """Loads models into memory to make running predictions fast."""
        print("Loading models...")
        controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)
        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
        )
        self.pipe.scheduler = UniPCMultistepScheduler.from_config(self.pipe.scheduler.config)
        self.pipe.enable_model_cpu_offload()
        print("Models loaded successfully.")

    def predict(
        self,
        image: Path = Input(description="Input image of a room"),
        prompt: str = Input(description="Style prompt for the new design"),
    ) -> Path:
        """Runs a single prediction on the model."""
        print("Processing input image...")
        input_image = Image.open(image).convert("RGB").resize((512, 512))

        # Perform Canny edge detection
        image_np = np.array(input_image)
        low_threshold = 100
        high_threshold = 200
        canny_image = cv2.Canny(image_np, low_threshold, high_threshold)
        canny_image = Image.fromarray(canny_image)

        print(f"Generating new design with prompt: '{prompt}'")
        generator = torch.manual_seed(0)
        output_image = self.pipe(
            prompt,
            num_inference_steps=30,
            generator=generator,
            image=canny_image
        ).images[0]
        
        # Save the output image to a temporary file
        output_path = Path("/tmp/output.png")
        output_image.save(output_path)
        
        print("Generation complete.")
        return output_path